{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==== Anlage des Spark Context ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark-Session erstellen und notwendige Frameworks importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/03 11:56:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    " \n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "#conf.set(\"spark.driver.bindAddress\", \"127.0.0.1\")  # Localhost\n",
    "#conf = conf.setMaster(\"local[*]\")\n",
    "conf = conf.setAppName(\"App\")\n",
    "\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==== Vorverarbeitung der Datenquelle ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# CSV-Datei laden, wobei das Pipe-Zeichen als Trennzeichen angegeben wird\n",
    "csv_file_path = \"data/output.csv\"  # Ersetze dies mit dem Pfad zu deiner CSV-Datei\n",
    "df = pd.read_csv(csv_file_path, sep='|')  # Verwende '|' als Trennzeichen\n",
    "\n",
    "# Angenommene Spaltennummern: time = 0, icao24 = 1, lat = 2, lon = 3, onground = 8\n",
    "column_indices = [0, 1, 2, 3, 8]  # Wir wählen nur die benötigten Spalten aus\n",
    "\n",
    "# Extrahieren der angegebenen Spalten, dabei behalten wir den Header (Spaltennamen)\n",
    "df_selected = df.iloc[:, column_indices]\n",
    "\n",
    "# Umbenennen der Spalten für bessere Lesbarkeit\n",
    "df_selected.columns = ['time', 'icao24', 'latitude', 'longitude', 'onground']\n",
    "\n",
    "# Funktion zur Konvertierung des Unix-Timestamps in das gewünschte Format\n",
    "def convert_timestamp(unix_timestamp):\n",
    "    try:\n",
    "        return datetime.utcfromtimestamp(int(unix_timestamp)).strftime('%Y/%m/%d %H:%M:%S')\n",
    "    except ValueError as e:\n",
    "        print(f\"Fehler beim Konvertieren des Timestamps: {unix_timestamp}, Fehler: {e}\")\n",
    "        return None\n",
    "\n",
    "# Umwandlung der 'time'-Spalte in das gewünschte Datumsformat\n",
    "df_selected['time'] = df_selected['time'].apply(convert_timestamp)\n",
    "\n",
    "# Umwandlung der 'onground'-Spalte, 'true' -> 1 und 'false' -> 0\n",
    "df_selected['onground'] = df_selected['onground'].apply(lambda x: 1 if str(x).strip().lower() == 'true' else 0)\n",
    "\n",
    "# Zeige die ersten 5 Zeilen des bearbeiteten DataFrames\n",
    "print(df_selected.head())\n",
    "\n",
    "# Speichere das Ergebnis als neue CSV-Datei, dabei bleibt der Header erhalten\n",
    "df_selected.to_csv(\"data/processed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==== Durchführen der Datenanlyse ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auswertung 1 - Weltweite Flughäfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse weltweiter Flughäfen und Heliports\n",
      "==================================================\n",
      "Die Anzahl der weltweiten Flughäfen und Heliports beträgt: 67961\n",
      "Davon Heliports: 21081\n",
      "Davon kleine Flughäfen: 41706\n",
      "Davon mittelgroße Flughäfen: 4700\n",
      "Davon große Flughäfen: 474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "def analyze_airports():\n",
    "    \"\"\"\n",
    "    Analysiert Flughäfen weltweit und gibt die Anzahl als String zurück.\n",
    "    \n",
    "    :return: Formatierten String mit den Ergebnissen und das zugehörige RDD.\n",
    "    \"\"\"\n",
    "\n",
    "    # Daten einlesen und Header extrahieren\n",
    "    airportRDD = sc.textFile(\"data/airports.csv\")\n",
    "    header = airportRDD.first()\n",
    "\n",
    "    # CSV korrekt parsen, um Fehler durch Kommata innerhalb von Anführungszeichen zu vermeiden\n",
    "    def parse_csv(line):\n",
    "        reader = csv.reader(StringIO(line))\n",
    "        return next(reader)\n",
    "\n",
    "    # Filterkriterien anwenden und nur die relevanten Spalten speichern (1, 2, 3, 4, 5, 7)\n",
    "    airportRDD = (\n",
    "        airportRDD.filter(lambda line: line != header)  # Header entfernen\n",
    "                  .map(parse_csv)  # CSV korrekt parsen\n",
    "                  .filter(lambda cols: len(cols) > 7)  # Sicherstellen, dass genug Spalten vorhanden sind\n",
    "                  .map(lambda cols: (cols[1].strip('\"'),  # Name\n",
    "                                    cols[2].strip('\"'),  # Typ\n",
    "                                    cols[3].strip('\"'),  # Breitengrad\n",
    "                                    cols[4].strip('\"'),  # Längengrad\n",
    "                                    cols[5].strip('\"'),  # Höhe\n",
    "                                    #cols[7].strip('\"')\n",
    "                                    ))  # Kontinent\n",
    "                  .filter(lambda cols: cols[1] in [\"small_airport\", \"medium_airport\", \"large_airport\", \"heliport\"])  # Nur bestimmte Typen\n",
    "    )\n",
    "\n",
    "    # Anzahl der Flughäfen insgesamt\n",
    "    total_airports = airportRDD.count()\n",
    "\n",
    "    # Anzahl der Flughäfen nach Kategorien\n",
    "    categorized_airports = (\n",
    "        airportRDD.map(lambda cols: cols[1])  # Typ (Spalte 2)\n",
    "                  .countByValue()\n",
    "    )\n",
    "\n",
    "    # Formatierte Ausgabe als String erstellen\n",
    "    result = \"Analyse weltweiter Flughäfen und Heliports\\n\"\n",
    "    result += \"=\" * 50 + \"\\n\"\n",
    "\n",
    "    result += f\"Die Anzahl der weltweiten Flughäfen und Heliports beträgt: {total_airports}\\n\"\n",
    "    result += f\"Davon Heliports: {categorized_airports.get('heliport', 0)}\\n\"\n",
    "    result += f\"Davon kleine Flughäfen: {categorized_airports.get('small_airport', 0)}\\n\"\n",
    "    result += f\"Davon mittelgroße Flughäfen: {categorized_airports.get('medium_airport', 0)}\\n\"\n",
    "    result += f\"Davon große Flughäfen: {categorized_airports.get('large_airport', 0)}\\n\"\n",
    "\n",
    "    return result, airportRDD\n",
    "\n",
    "# Beispielaufruf und Ausgabe\n",
    "result, airportRDD = analyze_airports()\n",
    "print(result)\n",
    "\n",
    "# Optional: Die Daten aus airportRDD anzeigen lassen\n",
    "#airportRDD.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auswertung 2 - Registrierte Flugobjekte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der weltweit gemeldeten, eindeutigen Flug- und Bodenobjekte: 601337\n",
      "==================================================\n",
      "Top 20 Airlines nach Anzahl der registrierten Flugzeuge:\n",
      "==================================================\n",
      "United States Air Force: 2223\n",
      "Delta Air Lines: 781\n",
      "American Airlines: 657\n",
      "Corporate Airlink: 649\n",
      "Federal Express: 560\n",
      "Royal Air Force: 503\n",
      "United Airlines: 451\n",
      "Southwest Airlines: 280\n",
      "German Air Force: 277\n",
      "Boeing: 274\n",
      "United Parcel Service: 270\n",
      "Indian Air Force: 236\n",
      "Force Aerienne Francaise: 223\n",
      "Gulfstream Aerospace: 201\n",
      "Bombardier: 190\n",
      "Ryanair: 159\n",
      "Qatar Airways: 157\n",
      "Skywest Airlines: 153\n",
      "Aeroflot Russian Airlines: 147\n",
      "Royal Netherlands Air Force: 144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_aircraft_data():\n",
    "    \n",
    "    \"\"\"\n",
    "    Analysiert eine CSV-Datei mit Flugzeugdaten, um die Gesamtanzahl der registrierten Flugobjekte \n",
    "    sowie die Top 20 Airlines nach der Anzahl der registrierten Flugzeuge zu ermitteln.\n",
    "\n",
    "    Die Funktion liest die Daten aus einer festgelegten CSV-Datei, filtert ungültige Einträge \n",
    "    und verarbeitet die Informationen mithilfe von Spark. \n",
    "\n",
    "    :return: Ein Tupel bestehend aus:\n",
    "        - result (str): Ein formatierter String mit der Gesamtanzahl der Flugobjekte \n",
    "                        und den Top 20 Airlines nach Anzahl registrierter Flugzeuge.\n",
    "        - aircraft_raw_rdd (RDD): Ein Spark RDD mit den gefilterten Flugzeugdaten.\n",
    "        - aircraftRDD (RDD): Ein Spark RDD, das die Airlines und die Anzahl ihrer Flugzeuge enthält.\n",
    "    \"\"\"\n",
    "\n",
    "    # Daten einlesen und Header extrahieren\n",
    "    aircraft_input_rdd = sc.textFile('data/aircraft-database-complete-2024-10.csv')\n",
    "    header = aircraft_input_rdd.first()\n",
    "\n",
    "    # Filterkriterien anwenden: Entfernen des Headers\n",
    "    aircraft_raw_rdd = aircraft_input_rdd.filter(lambda line: line != header)\n",
    "\n",
    "    # Anzahl der registrierten Flugobjekte\n",
    "    Anzahl_registrierte_Flugobjekte = aircraft_raw_rdd.count()\n",
    "\n",
    "    # RDD erstellen, um die Airlines nach Anzahl der registrierten Flugzeuge zu zählen\n",
    "    aircraftRDD = (\n",
    "        aircraft_raw_rdd.filter(lambda line: len(line.split(\",\")) > 16)\n",
    "        .map(lambda line: line.split(\",\")[17].strip('\"'))\n",
    "        .filter(lambda airline: airline != \"''\")\n",
    "        .map(lambda airline: (airline, 1))\n",
    "        .reduceByKey(lambda a, b: a + b)\n",
    "        .sortBy(lambda x: x[1], ascending=False)\n",
    "    )\n",
    "    \n",
    "    # Top 20 Airlines nach Anzahl der registrierten Flugzeuge\n",
    "    top_20_airlines = aircraftRDD.take(20)\n",
    "\n",
    "    # Ergebnis als formatierten String zurückgeben\n",
    "    result = f\"Anzahl der weltweit gemeldeten, eindeutigen Flug- und Bodenobjekte: {Anzahl_registrierte_Flugobjekte}\\n\"\n",
    "    result += \"=\" * 50 + \"\\n\"\n",
    "    result += \"Top 20 Airlines nach Anzahl der registrierten Flugzeuge:\\n\"\n",
    "    result += \"=\" * 50 + \"\\n\"\n",
    "\n",
    "    for airline, count in top_20_airlines:\n",
    "        result += f\"{airline}: {count}\\n\"\n",
    "\n",
    "    return result, aircraft_raw_rdd, aircraftRDD\n",
    "\n",
    "# Beispielaufruf und Ausgabe\n",
    "result, aircraft_raw_rdd, aircraftRDD = analyze_aircraft_data()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auswertung 3 - Weltweite Bewegungsdaten von Flugobjekten in einer Woche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/03 11:57:11 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "[Stage 18:======================================================> (59 + 2) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die erfassten Bewegungen von Flug- und Bodenobjekten wurden im Zeitraum vom 2024/11/19 10:36:44 bis zum 2024/11/26 13:59:59 (Zeitzone: UTC) ermittelt.\n",
      "==================================================\n",
      "Geografische Abdeckung:\n",
      "Längengrade: von -175.5147° bis 177.9875°\n",
      "Breitengrade: von -46.4715° bis 69.9645°\n",
      "Die Daten wurden in folgendem Luftraum erhoben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_fb706ce798996b23bd1613486a8f3be9 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_fb706ce798996b23bd1613486a8f3be9&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_fb706ce798996b23bd1613486a8f3be9 = L.map(\n",
       "                &quot;map_fb706ce798996b23bd1613486a8f3be9&quot;,\n",
       "                {\n",
       "                    center: [11.746490478515625, 1.2364087633130367],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 5,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_234162fa447b86d89427857c3f8362e8 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_234162fa447b86d89427857c3f8362e8.addTo(map_fb706ce798996b23bd1613486a8f3be9);\n",
       "        \n",
       "    \n",
       "            var rectangle_aea40bf234b430b5ec03e0c596ba962c = L.rectangle(\n",
       "                [[-46.471527099609375, -175.51465434412802], [69.96450805664062, 177.9874718707541]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;red&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 2}\n",
       "            ).addTo(map_fb706ce798996b23bd1613486a8f3be9);\n",
       "        \n",
       "    \n",
       "        var popup_483c02d9879d6d70f6f49188876b8a63 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_fbbf2703c21209e9c6a6fdff7307f15c = $(`&lt;div id=&quot;html_fbbf2703c21209e9c6a6fdff7307f15c&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Geographischer Bereich&lt;/div&gt;`)[0];\n",
       "                popup_483c02d9879d6d70f6f49188876b8a63.setContent(html_fbbf2703c21209e9c6a6fdff7307f15c);\n",
       "            \n",
       "        \n",
       "\n",
       "        rectangle_aea40bf234b430b5ec03e0c596ba962c.bindPopup(popup_483c02d9879d6d70f6f49188876b8a63)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x10d885940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "\n",
    "# Analyse der Bewegungsdaten\n",
    "def analyze_flight_movements(percentage=1.0):\n",
    "    \"\"\"\n",
    "    Analysiert Bewegungsdaten von Flugzeugen und erstellt eine Karte des geografischen Bereichs.\n",
    "    Misst dabei die Laufzeit für die Verarbeitung des Prozentsatzes der Daten.\n",
    "    \n",
    "    :param percentage: Prozentsatz (zwischen 0 und 1) der Daten, die geladen werden sollen (Standard: 100%)\n",
    "    :return: Die Ergebnisse der Auswertung, generierte Karte und das RDD der Daten sowie die benötigte Zeit\n",
    "    \"\"\"\n",
    "\n",
    "    if not 0 < percentage <= 1:\n",
    "        raise ValueError(\"Percentage muss zwischen 0 und 1 liegen\")\n",
    "    \n",
    "    # Einlesen der Bewegungsdaten eines definierten Zeitraums in einem bestimmten geografischen Bereich\n",
    "    myFileRDD = sc.textFile('data/processed_data.csv')\n",
    "    header = myFileRDD.take(2)\n",
    "    sampleRDD = myFileRDD.filter(lambda line: line not in header)\n",
    "\n",
    "    #Reduktion des RDDs auf Prozentwert an Datensätzen, seed sorgt für reproduzierbare Zufallsergebnisse (42 ist die Antwort auf alles).\n",
    "    dataRDD = sampleRDD.sample(False, percentage, seed=42)\n",
    "\n",
    "    #Erfassen des Zeitraums in dem Daten die erhoben wurden - Skalierbarkeit gegeben aufgrund der Rückgabe eines Wertes\n",
    "    start_time = dataRDD.map(lambda line: line.split(',')[0]).min()\n",
    "    end_time = dataRDD.map(lambda line: line.split(',')[0]).max()\n",
    "\n",
    "    #Geographische Analyse des betrachteten Luftraums - Skalierbarkeit gegeben aufgrund der Rückgabe und Visualisierung einzelner Werte\n",
    "\n",
    "    # Längengrade sortieren und auslesen\n",
    "    min_longitude = dataRDD.map(lambda line: float(line.split(',')[3])).min()\n",
    "    max_longitude = dataRDD.map(lambda line: float(line.split(',')[3])).max()\n",
    "\n",
    "    # Breitengrade (vermutlich Spalte mit Index 5 und 6)\n",
    "    min_latitude = dataRDD.map(lambda line: float(line.split(',')[2])).min()\n",
    "    max_latitude = dataRDD.map(lambda line: float(line.split(',')[2])).max()\n",
    "\n",
    "    # Zentrum des Bereichs berechnen\n",
    "    center_lat = (min_latitude + max_latitude) / 2\n",
    "    center_lon = (min_longitude + max_longitude) / 2\n",
    "    result_text = (\n",
    "        f\"Die erfassten Bewegungen von Flug- und Bodenobjekten wurden im Zeitraum vom \"\n",
    "        f\"{start_time.replace('\\\"', '').replace('+00', '')} bis zum \"\n",
    "        f\"{end_time.replace('\\\"', '').replace('+00', '')} (Zeitzone: UTC) ermittelt.\\n\"\n",
    "        f\"{'=' * 50}\\n\"\n",
    "        \"Geografische Abdeckung:\\n\"\n",
    "        f\"Längengrade: von {min_longitude:.4f}° bis {max_longitude:.4f}°\\n\"\n",
    "        f\"Breitengrade: von {min_latitude:.4f}° bis {max_latitude:.4f}°\\n\"\n",
    "        \"Die Daten wurden in folgendem Luftraum erhoben.\"\n",
    "    )\n",
    "\n",
    "    # Karte erstellen\n",
    "    map = folium.Map(location=[center_lat, center_lon], zoom_start=5)\n",
    "\n",
    "    # Rechteck auf der Karte hinzufügen\n",
    "    bounds = [[min_latitude, min_longitude], [max_latitude, max_longitude]]\n",
    "    folium.Rectangle(\n",
    "        bounds=bounds,\n",
    "        color=\"red\",\n",
    "        weight=2,\n",
    "        fill=True,\n",
    "        fill_color=\"blue\",\n",
    "        fill_opacity=0.2,\n",
    "        popup=\"Geographischer Bereich\"\n",
    "    ).add_to(map)\n",
    "\n",
    "    return result_text, map, dataRDD,  \n",
    "\n",
    "result_text, map_result, dataRDD = analyze_flight_movements()\n",
    "print(result_text)\n",
    "map_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auswertung 4 - Kombination Flugobjekte und Bewegungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restructure_flight_movements(dataRDD):\n",
    "    \"\"\"\n",
    "    Analyse der Bewegungsdaten nach Flug- und Bodenobjekten.\n",
    "\n",
    "    Args:\n",
    "        dataRDD: Ein RDD mit Roh-Bewegungsdaten.\n",
    "        percentage: Prozentsatz der Daten, die analysiert werden sollen.\n",
    "\n",
    "    Returns:\n",
    "        Ein transformierter RDD, gruppiert nach Flugzeug-ID, und die Anzahl der aktiven Flugzeuge.\n",
    "    \"\"\"\n",
    "    def parse_line(line):\n",
    "        parts = line.split(',')\n",
    "        return (\n",
    "            parts[1].strip(' \"\\t\\r\\n'),  # Key: Flugzeug-ID (icao24)\n",
    "            {  # Value: Alle relevanten Daten als Dictionary\n",
    "                \"time\": parts[0].strip('\"'),\n",
    "                \"lat\": float(parts[2].strip('\"')),\n",
    "                \"lon\": float(parts[3].strip('\"')),\n",
    "                \"onground\": int(parts[4].strip('\"'))\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # RDD transformieren: Gruppiere die Daten nach Flugzeug-ID\n",
    "    flights_rdd = dataRDD.map(parse_line).groupByKey().mapValues(list)\n",
    "\n",
    "    return flights_rdd\n",
    "\n",
    "flights_rdd = restructure_flight_movements(dataRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kombination der Bewegungsdaten mit den Daten der registrierten Flug- und Bodenobjekten\n",
    "\n",
    "def combine_rdds(flights_rdd, aircraft_raw_rdd):\n",
    "    \"\"\"\n",
    "    Kombiniert die Bewegungsdaten (flights_rdd) mit den Daten der registrierten Flug- und Bodenobjekte (aircraft_raw_rdd).\n",
    "\n",
    "    Args:\n",
    "        flights_rdd: Ein RDD mit Bewegungsdaten.\n",
    "        aircraft_raw_rdd: Ein RDD mit Rohdaten zu registrierten Flug- und Bodenobjekten.\n",
    "\n",
    "    Returns:\n",
    "        Ein kombiniertes RDD mit Flugzeug-ID, Flugdaten und Beschreibungen.\n",
    "    \"\"\"\n",
    "    def parse_type(line):\n",
    "        parts = line.split(',')\n",
    "        # Baseline-Verarbeitung ohne unnötige Komplexität\n",
    "        return (\n",
    "            parts[0].strip(\"'\"),  # Flugzeug-ID (icao24)\n",
    "            {\n",
    "                \"description\": parts[5].strip(\"'\") if len(parts) > 4 else \"\",\n",
    "                \"manufacturer\": parts[13].strip(\"'\") if len(parts) > 12 else \"\",\n",
    "                \"model\": parts[14].strip(\"'\") if len(parts) > 14 else \"\",\n",
    "                \"type\": parts[15].strip(\"'\") if len(parts) > 15 else \"\",\n",
    "                \"airline\": parts[18].strip(\"'\") if len(parts) > 16 else \"\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # RDD bereinigen und nur relevante Daten aufnehmen\n",
    "    cleaned_type_rdd = aircraft_raw_rdd.map(parse_type)\n",
    "\n",
    "    # Kombination der Bewegungsdaten mit der Beschreibung der registrierten Flug- und Bodenobjekten\n",
    "    result_rdd = flights_rdd.leftOuterJoin(cleaned_type_rdd)\n",
    "\n",
    "    # Kombination der Daten in einem RDD\n",
    "    combined_rdd = result_rdd.map(lambda x: (\n",
    "        x[0],  # Flugzeug-ID\n",
    "        {\n",
    "            \"aircraft_info\": x[1][1] if x[1][1] else {},  # Beschreibung, falls vorhanden\n",
    "            \"flight_data\": sorted(x[1][0], key=lambda entry: entry[\"time\"]) if x[1][0] else [] # Flugdaten sortiert nach Datum (lexografisch)\n",
    "        }\n",
    "    ))\n",
    "\n",
    "    return combined_rdd\n",
    "\n",
    "\n",
    "combined_rdd = combine_rdds(flights_rdd, aircraft_raw_rdd)\n",
    "#combined_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 462:==========================================>           (51 + 12) / 65]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Anzahl der im betrachteten Zeitraum aktiven Flug- und Bodenobjekte: 12104\n",
      "==================================================\n",
      "Flugzeuge mit den meisten Datensätzen (Top 5) sind: [('474805', 21485), ('440cab', 19321), ('440cac', 17565), ('ad976e', 17409), ('474809', 17093)]\n",
      " ==================================================\n",
      "Status der Objekt zum letzten gemessenen Zeitpunkt: \n",
      "Objekte aktuell in der Luft: 2050\n",
      "Objekte aktuell am Boden: 10054\n",
      "==================================================\n",
      "Im gesamten betrachteten Zeitraum sind: \n",
      "Objekte nur am Boden geblieben: 675\n",
      "Objekte nur in der Luft geblieben: 7780\n",
      "Objekte gestartet oder gelandet: 3649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Analyse des kombinierten RDDs (Bewegungsdaten + Beschreibung)\n",
    "\n",
    "def analyze_combined_rdd(sampleRDD, percentage=1.0):\n",
    "    \"\"\"\n",
    "    Analysiert ein kombiniertes RDD, das Bewegungsdaten von Flug- und Bodenobjekten enthält,\n",
    "    und liefert eine detaillierte statistische Zusammenfassung der betrachteten Daten.\n",
    "\n",
    "    Args:\n",
    "    sampleRDD (RDD): Ein RDD, das Flug- und Bewegungsdaten von Objekten enthält, wobei jedes Element ein Tupel ist,\n",
    "                      wobei das erste Element die Objekt-ID ist und das zweite Element ein Dictionary mit den Bewegungsdaten.\n",
    "    percentage (float): Der Anteil der Stichprobe (zwischen 0 und 1) der RDD-Daten, die für die Analyse verwendet werden sollen. \n",
    "                        Standardwert ist 1.0 (100%).\n",
    "\n",
    "    Returns:\n",
    "    str: Eine formatierte Zeichenkette, die die Ergebnisse der Analyse zusammenfasst, einschließlich der Gesamtzahl der\n",
    "         Objekte, der Flugzeuge mit den meisten Datensätzen und der Status- und Bewegungsanalyse für den betrachteten Zeitraum.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #Reduktion des RDDs auf Prozentwert an Datensätzen, seed sorgt für reproduzierbare Zufallsergebnisse (42 ist die Antwort auf alles).\n",
    "    combined_rdd = sampleRDD.sample(False, percentage, seed=42)\n",
    "    amount_of_aircrafts = combined_rdd.count()\n",
    "    result = \"=\" * 50 + \"\\n\"\n",
    "    result += f\"Anzahl der im betrachteten Zeitraum aktiven Flug- und Bodenobjekte: {amount_of_aircrafts}\\n\"\n",
    "    \n",
    "    #Ermittlung der Anzahl an Flug-Datensätze pro Flugzeug\n",
    "    countdatasetsRDD = combined_rdd.map(lambda x: (x[0],len(x[1]['flight_data']))).sortBy(lambda x: x[1], ascending=False)\n",
    "    first_5_elements = countdatasetsRDD.take(5)\n",
    "    result += \"=\" * 50 + \"\\n\"\n",
    "    result += f\"Flugzeuge mit den meisten Datensätzen (Top 5) sind: {first_5_elements}\\n \"\n",
    "    result += \"=\" * 50 + \"\\n\"\n",
    "\n",
    "\n",
    "    # Bestimmung der Positon - Skalierbarkeit gegeben über Betrachtung einzelner Werte\n",
    "    airRDD = combined_rdd.map(lambda x: (x[0], x[1]['flight_data'][-1][\"onground\"]))\n",
    "    onground = airRDD.filter(lambda x: x[1]==1).count()\n",
    "    inair = airRDD.filter(lambda x: x[1]==0).count()\n",
    "    result += f\"Status der Objekt zum letzten gemessenen Zeitpunkt: \\n\"\n",
    "    result += f\"Objekte aktuell in der Luft: {onground}\\n\"\n",
    "    result += f\"Objekte aktuell am Boden: {inair}\\n\"\n",
    "\n",
    "\n",
    "    # Ermittlung der Position im Zeitraum - Skalierbarkeit gegeben über Betrachtung einzelner Werte\n",
    "    nextRDD = combined_rdd.map(lambda x: (x[0], sum(datapoint[\"onground\"] for datapoint in x[1]['flight_data']), len(x[1]['flight_data'])))\n",
    "    calculatedRDD = nextRDD.map(lambda x: (x[0], x[1]/x[2]))\n",
    "    startet_or_landed = calculatedRDD.filter(lambda x: x[1] < 1 and x[1] >0).count()\n",
    "    not_started = calculatedRDD.filter(lambda x: x[1] == 1).count()\n",
    "    not_landed = calculatedRDD.filter(lambda x: x[1] == 0).count()\n",
    "\n",
    "    result += \"=\" * 50 + \"\\n\"\n",
    "    result += f\"Im gesamten betrachteten Zeitraum sind: \\n\"\n",
    "    result += f\"Objekte nur am Boden geblieben: {not_started}\\n\"\n",
    "    result += f\"Objekte nur in der Luft geblieben: {not_landed}\\n\"\n",
    "    result += f\"Objekte gestartet oder gelandet: {startet_or_landed}\"\n",
    "\n",
    "\n",
    "    return combined_rdd, result\n",
    "\n",
    "combined_analyzed_rdd, result = analyze_combined_rdd(combined_rdd)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==== Visuelle Analysen ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Haversine-Funktion zum Berechnen der Distanz zwischen zwei Punkten\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Erd-Radius in Kilometern\n",
    "    d_lat = math.radians(lat2 - lat1)\n",
    "    d_lon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(d_lat / 2.0) ** 2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(d_lon / 2.0) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def find_nearest_airport(lat, lon, airports):\n",
    "    \"\"\"\n",
    "    Findet den nächsten Flughafen zu gegebenen Koordinaten innerhalb von 10 km.\n",
    "    Gibt den Flughafen mit der geringsten Distanz zurück.\n",
    "    \"\"\"\n",
    "    nearest_airport = None\n",
    "    min_distance = float(\"inf\")\n",
    "\n",
    "    for airport in airports:\n",
    "        airport_id, _, airport_name, airport_lat, airport_lon = airport\n",
    "        airport_lat = float(airport_lat)\n",
    "        airport_lon = float(airport_lon)\n",
    "        distance = haversine(lat, lon, airport_lat, airport_lon)\n",
    "        if distance <= 10 and distance < min_distance:  # Innerhalb von 10 km und geringste Distanz\n",
    "            min_distance = distance\n",
    "            nearest_airport = (airport_id, airport_name)\n",
    "\n",
    "    if nearest_airport:\n",
    "        return nearest_airport\n",
    "    return None, None\n",
    "\n",
    "def extract_flights_with_airports(record, airports):\n",
    "    \"\"\"\n",
    "    Extrahiert Flüge und fügt Flughafendaten hinzu.\n",
    "    \"\"\"\n",
    "    icao24, combined_rdd = record\n",
    "    aircraft_info = combined_rdd['aircraft_info']\n",
    "    flight_data = combined_rdd['flight_data']\n",
    "\n",
    "    # Filter: Ignoriere Datensätze mit \"Surface Vehicle\" in der Beschreibung\n",
    "    if 'description' in aircraft_info and 'Surface Vehicle' in aircraft_info['description']:\n",
    "        return []\n",
    "\n",
    "    flights = []\n",
    "    current_flight = []\n",
    "    in_flight = False\n",
    "    previous_entry = None  # Variable, um den vorherigen Datensatz zu speichern\n",
    "\n",
    "    for entry in flight_data:\n",
    "        # Überprüfung, ob es sich um einen Start handelt\n",
    "        if not in_flight and entry['onground'] == 0 and previous_entry and previous_entry['onground'] == 1:\n",
    "            in_flight = True\n",
    "            current_flight = [entry]  # Startpunkt hinzufügen\n",
    "        elif in_flight and entry['onground'] == 1:  # Landung erkannt\n",
    "            current_flight.append(entry)  # Landepunkt hinzufügen\n",
    "            # Flug-Informationen extrahieren\n",
    "            start = current_flight[0]\n",
    "            end = current_flight[-1]\n",
    "\n",
    "            start_airport_id, start_airport_name = find_nearest_airport(start['lat'], start['lon'], airports)\n",
    "            end_airport_id, end_airport_name = find_nearest_airport(end['lat'], end['lon'], airports)\n",
    "\n",
    "            flight_info = {\n",
    "                'start_time': start['time'],\n",
    "                'start_coords': (start['lat'], start['lon']),\n",
    "                'start_airport': {'id': start_airport_id, 'name': start_airport_name},\n",
    "                'end_time': end['time'],\n",
    "                'end_coords': (end['lat'], end['lon']),\n",
    "                'end_airport': {'id': end_airport_id, 'name': end_airport_name},\n",
    "            }\n",
    "            flights.append((icao24, aircraft_info, flight_info))\n",
    "            in_flight = False\n",
    "            current_flight = []\n",
    "        elif in_flight:  # Punkte während des Fluges sammeln\n",
    "            current_flight.append(entry)\n",
    "\n",
    "        # Speichere den aktuellen Eintrag als vorherigen für die nächste Iteration\n",
    "        previous_entry = entry\n",
    "\n",
    "    return flights\n",
    "\n",
    "# Airports-Daten als Liste sammeln (Broadcast-Variable verwenden)\n",
    "# Annahme: airportRDD ist das gegebene RDD mit den Flughafendaten\n",
    "airports_list = airportRDD.collect()\n",
    "broadcast_airports = sc.broadcast(airports_list)\n",
    "\n",
    "# Anwenden der Extraktionsfunktion auf die RDD mit Flughafendaten\n",
    "flights_rdd = combined_rdd.flatMap(lambda record: extract_flights_with_airports(record, broadcast_airports.value))\n",
    "\n",
    "# Sammle alle Daten aus dem RDD\n",
    "all_flights = flights_rdd.collect()\n",
    "\n",
    "# Gib alle gesammelten Flugdaten aus\n",
    "for flight in all_flights:\n",
    "    print(flight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Beispiel-Daten erweitern: Liste von Flügen\n",
    "flights_data = flights_rdd.collect()\n",
    "\n",
    "# Schritt 1: Flugverbindungen aggregieren (Start- und End-Airport-Paare zählen)\n",
    "connections = defaultdict(int)\n",
    "start_end_names = {}\n",
    "\n",
    "for _, _, flight_info in flights_data:\n",
    "    start_airport = flight_info['start_airport']\n",
    "    end_airport = flight_info['end_airport']\n",
    "    \n",
    "    if start_airport['id'] and end_airport['id']:  # Nur valide Airports berücksichtigen\n",
    "        start_id, start_name = start_airport['id'], start_airport['name']\n",
    "        end_id, end_name = end_airport['id'], end_airport['name']\n",
    "        \n",
    "        connections[(start_id, end_id)] += 1\n",
    "        start_end_names[start_id] = start_name\n",
    "        start_end_names[end_id] = end_name\n",
    "\n",
    "# Schritt 2: Netzwerkdiagramm erstellen\n",
    "G = nx.Graph()\n",
    "\n",
    "# Knoten und Kanten hinzufügen (nur Verbindungen mit mehr als 5 Flügen)\n",
    "for (start, end), weight in connections.items():\n",
    "    if weight > 5:  # Filter: Nur Verbindungen > 5\n",
    "        G.add_edge(start, end, weight=weight)\n",
    "\n",
    "# Schritt 3: Positionen berechnen\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Knoten und Kanten für Plotly vorbereiten\n",
    "edges_x = []\n",
    "edges_y = []\n",
    "weights = []\n",
    "\n",
    "for edge in G.edges(data=True):\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edges_x.extend([x0, x1, None])\n",
    "    edges_y.extend([y0, y1, None])\n",
    "    weights.append(edge[2]['weight'])\n",
    "\n",
    "# Knoten vorbereiten\n",
    "nodes_x = []\n",
    "nodes_y = []\n",
    "node_text = []\n",
    "\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    nodes_x.append(x)\n",
    "    nodes_y.append(y)\n",
    "    node_text.append(start_end_names.get(node, node))  # Namen verwenden\n",
    "\n",
    "# Schritt 4: Interaktives Diagramm mit Plotly erstellen\n",
    "fig = go.Figure()\n",
    "\n",
    "# Kanten hinzufügen mit stärkerer Gewichtung\n",
    "max_weight = max(weights) if weights else 1  # Maximale Gewichtung für Skalierung\n",
    "\n",
    "for i, edge in enumerate(G.edges(data=True)):\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[x0, x1, None],\n",
    "        y=[y0, y1, None],\n",
    "        line=dict(width=(weights[i] / max_weight) * 100, color='black'),  # Stärkere Skalierung (100-fach)\n",
    "        hoverinfo='none',\n",
    "        mode='lines'))\n",
    "\n",
    "# Knoten hinzufügen\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=nodes_x, y=nodes_y,\n",
    "    mode='markers+text',\n",
    "    text=node_text,\n",
    "    textposition=\"top center\",\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        color='skyblue',\n",
    "        line_width=2),\n",
    "    hoverinfo='text'))\n",
    "\n",
    "# Layout anpassen\n",
    "fig.update_layout(\n",
    "    title=\"Interaktives Netzwerkdiagramm der Flugverbindungen (Verbindungen > 5)\",\n",
    "    title_x=0.5,\n",
    "    showlegend=False,\n",
    "    hovermode='closest',\n",
    "    margin=dict(b=0, l=0, r=0, t=30),\n",
    "    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "# Interaktives Diagramm anzeigen\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisierung der Bewegung und Beschreibung eines ausgewählten Flug- oder Bodenobjektes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from IPython.display import display\n",
    "\n",
    "def analyze_aircraft_route(selected_icao):\n",
    "    # Filtere die Daten für die spezifische Flugzeug-ID im RDD\n",
    "    filtered_data = combined_rdd.filter(lambda x: x[0] == selected_icao).collect()\n",
    "\n",
    "    if filtered_data:\n",
    "        # Hole die Daten für das ausgewählte Flugzeug\n",
    "        icao24, route_data = filtered_data[0]\n",
    "        aircraft_info = route_data[\"aircraft_info\"]  # Zugriff auf die Flugzeugbeschreibung\n",
    "        flight_data = route_data[\"flight_data\"]  # Zugriff auf die Flugdaten\n",
    "\n",
    "        print(f\"Flugzeug-ID: {icao24}\")\n",
    "\n",
    "        # Erstelle die Karte, zentriert auf den ersten Datenpunkt\n",
    "        first_lat = flight_data[0][\"lat\"]\n",
    "        first_lon = flight_data[0][\"lon\"]\n",
    "        map = folium.Map(location=[first_lat, first_lon], zoom_start=12)\n",
    "\n",
    "        # Zeichne Linien zwischen aufeinanderfolgenden Punkten\n",
    "        for i in range(len(flight_data) - 1):\n",
    "            point_a = flight_data[i]\n",
    "            point_b = flight_data[i + 1]\n",
    "\n",
    "            # Zeichne nur Linien, wenn beide Punkte gültige Koordinaten haben\n",
    "            if point_a[\"lat\"] and point_a[\"lon\"] and point_b[\"lat\"] and point_b[\"lon\"]:\n",
    "                folium.PolyLine(\n",
    "                    locations=[(point_a[\"lat\"], point_a[\"lon\"]), (point_b[\"lat\"], point_b[\"lon\"])],\n",
    "                    color=\"blue\",\n",
    "                    weight=2.5,\n",
    "                    opacity=0.8\n",
    "                ).add_to(map)\n",
    "\n",
    "        # Füge Marker nur für Landepunkte hinzu\n",
    "        for point in flight_data:\n",
    "            if point[\"onground\"] == 1:  # Nur Landepunkte anzeigen\n",
    "                folium.Marker(\n",
    "                    location=(point[\"lat\"], point[\"lon\"]),\n",
    "                    popup=f\"Zeit: {point['time']}<br>Am Boden: {point['onground']}<br>Hersteller: {aircraft_info['manufacturer']}<br>Flugzeugtyp: {aircraft_info['model']}<br>Airline: {aircraft_info['airline']}\",\n",
    "                    icon=folium.Icon(color=\"green\", icon=\"info-sign\")\n",
    "                ).add_to(map)\n",
    "\n",
    "        # Rückgabe der Karte\n",
    "        return map\n",
    "\n",
    "    else:\n",
    "        return f\"Keine Daten für Flugzeug-ID '{selected_icao}' gefunden.\"\n",
    "\n",
    "\n",
    "result = analyze_aircraft_route(\"c04fdd\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisierung der Bewegung und Beschreibung mehrerer, zufällig ausgewählter Flug- oder Bodenobjekte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from IPython.display import display\n",
    "import random\n",
    "\n",
    "# Zufällige Farben für die Flugzeuge\n",
    "def get_random_color():\n",
    "    return \"#{:06x}\".format(random.randint(0, 0xFFFFFF))\n",
    "\n",
    "def analyze_aircraft_routes(number_of_samples):\n",
    "    # Nimm eine beliebige Anzahl zufälliger Flugzeuge aus dem RDD\n",
    "    random_aircrafts = combined_rdd.takeSample(withReplacement=False, num=number_of_samples)\n",
    "\n",
    "    # Erstelle eine Karte, zentriert auf einen Beispielpunkt\n",
    "    if random_aircrafts:\n",
    "        # Hole den ersten Punkt zur Zentrierung der Karte\n",
    "        first_lat = random_aircrafts[0][1][\"flight_data\"][0][\"lat\"]\n",
    "        first_lon = random_aircrafts[0][1][\"flight_data\"][0][\"lon\"]\n",
    "        map = folium.Map(location=[first_lat, first_lon], zoom_start=6)\n",
    "\n",
    "        # Iteriere über die zufälligen Flugzeuge\n",
    "        for icao24, data in random_aircrafts:\n",
    "            aircraft_info = data[\"aircraft_info\"]  # Infos über das Flugzeug\n",
    "            flight_data = data[\"flight_data\"]      # Flugdaten\n",
    "\n",
    "            # Sichere Abfrage von Typ, Modell und Hersteller mit Standardwerten\n",
    "            aircraft_type = aircraft_info.get(\"type\", \"Unknown\")\n",
    "            aircraft_model = aircraft_info.get(\"model\", \"Unknown\")\n",
    "            aircraft_manufacturer = aircraft_info.get(\"manufacturer\", \"Unknown\")\n",
    "            aircraft_airline = aircraft_info.get(\"airline\", \"Unknown\")\n",
    "\n",
    "            # Generiere eine zufällige Farbe für die Linien\n",
    "            color = get_random_color()\n",
    "\n",
    "            # Zeichne Linien zwischen aufeinanderfolgenden Punkten\n",
    "            for i in range(len(flight_data) - 1):\n",
    "                point_a = flight_data[i]\n",
    "                point_b = flight_data[i + 1]\n",
    "\n",
    "                # Zeichne nur Linien, wenn beide Punkte gültige Koordinaten haben\n",
    "                if point_a[\"lat\"] and point_a[\"lon\"] and point_b[\"lat\"] and point_b[\"lon\"]:\n",
    "                    folium.PolyLine(\n",
    "                        locations=[(point_a[\"lat\"], point_a[\"lon\"]), (point_b[\"lat\"], point_b[\"lon\"])],\n",
    "                        color=color,\n",
    "                        weight=2.5,\n",
    "                        opacity=0.8\n",
    "                    ).add_to(map)\n",
    "\n",
    "            # Füge Marker nur für Landepunkte hinzu\n",
    "            for point in flight_data:\n",
    "                if point[\"onground\"] == 1:  # Nur Landepunkte anzeigen\n",
    "                    folium.Marker(\n",
    "                        location=(point[\"lat\"], point[\"lon\"]),\n",
    "                        popup=(\n",
    "                            f\"Flugzeug: {icao24}<br>\"\n",
    "                            f\"Hersteller: {aircraft_manufacturer}<br>\"\n",
    "                            f\"Modell: {aircraft_model}<br>\"\n",
    "                            f\"Airline: {aircraft_airline}<br>\"\n",
    "                            f\"Zeit: {point['time']}<br>\"\n",
    "                            f\"Am Boden: {point['onground']}\"\n",
    "                        ),\n",
    "                        icon=folium.Icon(color=\"green\", icon=\"info-sign\")\n",
    "                    ).add_to(map)\n",
    "\n",
    "        # Zeige die Karte im Notebook\n",
    "        return map\n",
    "    else:\n",
    "        return \"Keine Daten gefunden.\"\n",
    "    \n",
    "result = analyze_aircraft_routes(20)\n",
    "display(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap zur visuellen Auswertung aller Bewegungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Map und Filter: Direktes Überprüfen der Konvertierbarkeit in float\n",
    "# 1 Dezimalstelle: ~11,1 km Genauigkeit eine Nachkommastelle reicht für globale Karten oder grobe Cluster.\n",
    "# 2 Dezimalstellen: ~1,1 km Genauigkeit gut für Städte oder Regionen.\n",
    "# 3 Dezimalstellen: ~110 m Genauigkeit ideal für Stadtviertel oder grobe Stadtanalysen.\n",
    "# Ab 3 Nachkommastellen geht nix mehr\n",
    "\n",
    "def extract_coordinates(line):\n",
    "    try:\n",
    "        parts = line.split(',')\n",
    "        return round(float(parts[3]), 2), round(float(parts[4]), 2)  # Breitengrad, Längengrad\n",
    "    except (ValueError, IndexError):\n",
    "        return None  # Falls Konvertierung oder Zugriff fehlschlägt\n",
    "\n",
    "location_rdd = dataRDD.map(extract_coordinates).filter(lambda x: x is not None)\n",
    "\n",
    "number = location_rdd.count()\n",
    "print(f\"Anzahl der Daten vor der Reduktion {number}\")\n",
    "\n",
    "\n",
    "# Map-Reduce: Zähle, wie oft jede Kombination von Breitengrad und Längengrad vorkommt\n",
    "coordinate_counts = location_rdd.map(lambda coord: (coord, 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(coordinate_counts.take(5))\n",
    "print(f\"Anzahl Koordinaten nach der Reduktion {coordinate_counts.count()}\")\n",
    "\n",
    "# Beispiel: Aggregierte Koordinaten mit Häufigkeiten (ersetzt durch deine Daten)\n",
    "aggregated_data = coordinate_counts.collect()\n",
    "\n",
    "# Vorbereitung der Heatmap-Daten\n",
    "heatmap_data = [(lat_lon[0], lat_lon[1], count) for lat_lon, count in aggregated_data]\n",
    "\n",
    "# Erstelle die Karte\n",
    "if heatmap_data:\n",
    "    # Zentriere die Karte auf den ersten Punkt und passe die Zoom-Stufe an\n",
    "    map = folium.Map(location=[heatmap_data[0][0], heatmap_data[0][1]], zoom_start=6)\n",
    "\n",
    "    # HeatMap hinzufügen (Radius und max_zoom können angepasst werden)\n",
    "    HeatMap(heatmap_data, radius=15, max_zoom=13).add_to(map)\n",
    "\n",
    "    # Karte anzeigen\n",
    "    display(map)\n",
    "else:\n",
    "    print(\"Keine gültigen Punkte für die Heatmap gefunden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==== Untersuchung der Analysen ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition der Analyse- und Fehlertoleranz-Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mcpu_stress\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Simulieren von Netzwerkfehlern (Ausfall der Kommunikation im Netzwerk)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate_network_failure\u001b[39m():\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# Blockiere Loopback-Kommunikation (127.0.0.1), die Spark nutzt\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 76\u001b[0m, in \u001b[0;36mcpu_stress\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcpu_stress\u001b[39m():\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import datetime\n",
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "def get_system_info():\n",
    "    # CPU-Informationen\n",
    "    cpu_count = psutil.cpu_count(logical=False)  # Anzahl physikalischer CPU-Kerne\n",
    "    logical_cpu_count = psutil.cpu_count(logical=True)  # Anzahl logischer CPUs (mit Hyper-Threading)\n",
    "    cpu_freq = psutil.cpu_freq()  # CPU Frequenz\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)  # CPU-Auslastung in Prozent\n",
    "\n",
    "    # RAM-Informationen\n",
    "    virtual_memory = psutil.virtual_memory()  # Virtueller Speicher (RAM)\n",
    "    total_memory = virtual_memory.total  # Gesamtgröße des RAM\n",
    "    available_memory = virtual_memory.available  # Verfügbarer RAM\n",
    "    used_memory = virtual_memory.used  # Genutzter RAM\n",
    "    memory_percent = virtual_memory.percent  # Prozentsatz des verwendeten RAM\n",
    "\n",
    "\n",
    "    # Ausgabe der gesammelten Informationen\n",
    "    result = \"=\" * 50\n",
    "    result += \"System Informationsübersicht\"\n",
    "    result += \"=\" * 50\\\n",
    "\n",
    "    result += \"\\nCPU Infos:\\n\"\n",
    "    result += f\"  - Anzahl der physischen CPU-Kerne: {cpu_count}\\n\"\n",
    "    result += f\"  - Anzahl der logischen CPU-Kerne (inkl. Hyper-Threading): {logical_cpu_count}\\n\"\n",
    "    result += f\"  - Aktuelle CPU Frequenz: {cpu_freq.current} MHz\\n\"\n",
    "    result += f\"  - Aktuelle CPU Auslastung: {cpu_percent}%\\n\"\n",
    "\n",
    "    result += \"\\nRAM Infos:\\n\"\n",
    "    result += f\"  - Gesamter RAM: {total_memory / (1024 ** 3):.2f} GB\\n\"\n",
    "    result += f\"  - Verfügbarer RAM: {available_memory / (1024 ** 3):.2f} GB\\n\"\n",
    "    result += f\"  - Genutzter RAM: {used_memory / (1024 ** 3):.2f} GB\\n\"\n",
    "    result += f\"  - RAM Auslastung: {memory_percent}%\"\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Datenverteilung im CLuster\n",
    "def analyze_partition_distribution(rdd):\n",
    "    \"\"\"\n",
    "    Analysiert die Verteilung der Daten in einem RDD über die Partitionen.\n",
    "\n",
    "    :param rdd: Das RDD, das analysiert werden soll.\n",
    "    \"\"\"\n",
    "    # Funktion, um die Größe jeder Partition zu berechnen\n",
    "    def partition_sizes(index, iterator):\n",
    "        yield index, sum(1 for _ in iterator)\n",
    "\n",
    "   # Daten je Partition sammeln\n",
    "    partition_info = rdd.mapPartitionsWithIndex(partition_sizes).collect()\n",
    "\n",
    "    # Anzahl der Partitionen ermitteln\n",
    "    num_partitions = rdd.getNumPartitions()\n",
    "\n",
    "    #Ergebnisse formatieren\n",
    "    number_data = f\"Anzahl der Datensätze: {rdd.count()}\\n\"\n",
    "    number_partition = f\"Anzahl der Partitionen: {num_partitions}\\n\"\n",
    "    result = \"Datenverteilung auf Partitionen:\\n\"\n",
    "\n",
    "    # Ausgabe der Verteilung pro Partition\n",
    "    for partition, size in partition_info:\n",
    "        result += f\"Partition {partition}: {size} Datensätze\\n\"\n",
    "\n",
    "    return number_data, number_partition, result\n",
    "\n",
    "\n",
    "# Fehlertoleranz\n",
    "\n",
    "# Prozess, der die CPU lokal belastet\n",
    "def cpu_stress():\n",
    "    while True:\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cpu_stress()\n",
    "\n",
    "\n",
    "# Simulieren von Netzwerkfehlern (Ausfall der Kommunikation im Netzwerk)\n",
    "def simulate_network_failure():\n",
    "    # Blockiere Loopback-Kommunikation (127.0.0.1), die Spark nutzt\n",
    "    os.system(\"iptables -A INPUT -s 127.0.0.1 -j DROP\")\n",
    "\n",
    "def restore_network():\n",
    "    # Entferne die Blockade\n",
    "    os.system(\"iptables -D INPUT -s 127.0.0.1 -j DROP\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardwareanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================System Informationsübersicht==================================================\n",
      "CPU Infos:\n",
      "  - Anzahl der physischen CPU-Kerne: 12\n",
      "  - Anzahl der logischen CPU-Kerne (inkl. Hyper-Threading): 12\n",
      "  - Aktuelle CPU Frequenz: 4056 MHz\n",
      "  - Aktuelle CPU Auslastung: 11.3%\n",
      "\n",
      "RAM Infos:\n",
      "  - Gesamter RAM: 36.00 GB\n",
      "  - Verfügbarer RAM: 10.06 GB\n",
      "  - Genutzter RAM: 17.58 GB\n",
      "  - RAM Auslastung: 72.1%\n"
     ]
    }
   ],
   "source": [
    "# Hardwareanalyse\n",
    "print(get_system_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse 1 - Europäische Flughäfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Funktion hat 0.3296 Sekunden benötigt\n",
      "Anzahl der Datensätze: 67961\n",
      "Anzahl der Partitionen: 2\n",
      "\n",
      "Datenverteilung auf Partitionen:\n",
      "Partition 0: 34380 Datensätze\n",
      "Partition 1: 33581 Datensätze\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Laufzeit\n",
    "start_time = time.time()\n",
    "analyze_airports()\n",
    "end_time = time.time()\n",
    "print(f\"Die Funktion hat {(end_time - start_time):.4f} Sekunden benötigt\")\n",
    "\n",
    "#Datenverteilung\n",
    "number_data, number_partition, result = analyze_partition_distribution(airportRDD)\n",
    "print(number_data + number_partition + \"\\n\" + result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse 2 - Flugzeugbeschreibungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Funktion hat 0.8380 Sekunden benötigt\n",
      "Anzahl der Datensätze: 4581\n",
      "Anzahl der Partitionen: 4\n",
      "\n",
      "Datenverteilung auf Partitionen:\n",
      "Partition 0: 1084 Datensätze\n",
      "Partition 1: 880 Datensätze\n",
      "Partition 2: 0 Datensätze\n",
      "Partition 3: 2617 Datensätze\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Laufzeit\n",
    "start_time = time.time()\n",
    "analyze_aircraft_data()\n",
    "end_time = time.time()\n",
    "print(f\"Die Funktion hat {(end_time - start_time):.4f} Sekunden benötigt\")\n",
    "\n",
    "#Datenverteilung\n",
    "number_data, number_partition, result = analyze_partition_distribution(aircraftRDD)\n",
    "print(number_data + number_partition + \"\\n\" + result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse 3 - Bewegungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#Laufzeit\n",
    "start_time = time.time()\n",
    "result_text, map_result, dataRDD = analyze_flight_movements(percentage=1.0)\n",
    "end_time = time.time()\n",
    "print(f\"Die Funktion hat für 100% der Daten {(end_time - start_time):.4f} Sekunden benötigt\")\n",
    "print(result_text)\n",
    "print()\n",
    "\n",
    "#Datenverteilung\n",
    "number_data, number_partition, result = analyze_partition_distribution(dataRDD)\n",
    "print(number_data + number_partition + result)\n",
    "\n",
    "\n",
    "#Skalierbarkeit\n",
    "percentages = [0.1, 0.2, 0.5, 1.0]  # 10%, 20%, 50%, 100%\n",
    "\n",
    "for percentage in percentages:\n",
    "    print(f\"\\nVerarbeite {percentage*100}% der Daten...\")\n",
    "    start_time = time.time()\n",
    "    result_text, map_result, dataRDD = analyze_flight_movements(percentage=percentage)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Verarbeitungszeit für {percentage*100}% der Daten: {(end_time-start_time):.2f} Sekunden\")\n",
    "    number_data, number_partition, result = analyze_partition_distribution(dataRDD)\n",
    "    print(number_data + number_partition)\n",
    "    print(f\"Anzahl der Worker Nodes: {len(sc._jsc.sc().statusTracker().getExecutorInfos()) - 1}\")  # -1 für den Treiber\n",
    "    print(f\"Gesamte Anzahl der Kerne: {sc.defaultParallelism}\")\n",
    "\n",
    "# Fehlertoleranz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse 4 - Kombinierte Flugobekte und Bewegungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Funktion hat für 100% der Daten 57.2920 Sekunden benötigt\n",
      "==================================================\n",
      "Anzahl der im betrachteten Zeitraum aktiven Flug- und Bodenobjekte: 12104\n",
      "==================================================\n",
      "Flugzeuge mit den meisten Datensätzen (Top 5) sind: [('474805', 21485), ('440cab', 19321), ('440cac', 17565), ('ad976e', 17409), ('474809', 17093)]\n",
      " ==================================================\n",
      "Status der Objekt zum letzten gemessenen Zeitpunkt: \n",
      "Objekte aktuell in der Luft: 2050\n",
      "Objekte aktuell am Boden: 10054\n",
      "==================================================\n",
      "Im gesamten betrachteten Zeitraum sind: \n",
      "Objekte nur am Boden geblieben: 675\n",
      "Objekte nur in der Luft geblieben: 7780\n",
      "Objekte gestartet oder gelandet: 3649\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Datensätze: 12104\n",
      "Anzahl der Partitionen: 65\n",
      "Datenverteilung auf Partitionen:\n",
      "Partition 0: 206 Datensätze\n",
      "Partition 1: 184 Datensätze\n",
      "Partition 2: 229 Datensätze\n",
      "Partition 3: 195 Datensätze\n",
      "Partition 4: 182 Datensätze\n",
      "Partition 5: 189 Datensätze\n",
      "Partition 6: 210 Datensätze\n",
      "Partition 7: 173 Datensätze\n",
      "Partition 8: 198 Datensätze\n",
      "Partition 9: 187 Datensätze\n",
      "Partition 10: 186 Datensätze\n",
      "Partition 11: 203 Datensätze\n",
      "Partition 12: 178 Datensätze\n",
      "Partition 13: 177 Datensätze\n",
      "Partition 14: 211 Datensätze\n",
      "Partition 15: 163 Datensätze\n",
      "Partition 16: 191 Datensätze\n",
      "Partition 17: 184 Datensätze\n",
      "Partition 18: 185 Datensätze\n",
      "Partition 19: 197 Datensätze\n",
      "Partition 20: 198 Datensätze\n",
      "Partition 21: 185 Datensätze\n",
      "Partition 22: 178 Datensätze\n",
      "Partition 23: 192 Datensätze\n",
      "Partition 24: 155 Datensätze\n",
      "Partition 25: 181 Datensätze\n",
      "Partition 26: 174 Datensätze\n",
      "Partition 27: 163 Datensätze\n",
      "Partition 28: 199 Datensätze\n",
      "Partition 29: 171 Datensätze\n",
      "Partition 30: 178 Datensätze\n",
      "Partition 31: 177 Datensätze\n",
      "Partition 32: 167 Datensätze\n",
      "Partition 33: 189 Datensätze\n",
      "Partition 34: 183 Datensätze\n",
      "Partition 35: 167 Datensätze\n",
      "Partition 36: 192 Datensätze\n",
      "Partition 37: 172 Datensätze\n",
      "Partition 38: 175 Datensätze\n",
      "Partition 39: 185 Datensätze\n",
      "Partition 40: 171 Datensätze\n",
      "Partition 41: 159 Datensätze\n",
      "Partition 42: 196 Datensätze\n",
      "Partition 43: 196 Datensätze\n",
      "Partition 44: 178 Datensätze\n",
      "Partition 45: 185 Datensätze\n",
      "Partition 46: 209 Datensätze\n",
      "Partition 47: 182 Datensätze\n",
      "Partition 48: 204 Datensätze\n",
      "Partition 49: 177 Datensätze\n",
      "Partition 50: 179 Datensätze\n",
      "Partition 51: 189 Datensätze\n",
      "Partition 52: 178 Datensätze\n",
      "Partition 53: 207 Datensätze\n",
      "Partition 54: 191 Datensätze\n",
      "Partition 55: 170 Datensätze\n",
      "Partition 56: 191 Datensätze\n",
      "Partition 57: 201 Datensätze\n",
      "Partition 58: 171 Datensätze\n",
      "Partition 59: 191 Datensätze\n",
      "Partition 60: 196 Datensätze\n",
      "Partition 61: 177 Datensätze\n",
      "Partition 62: 197 Datensätze\n",
      "Partition 63: 192 Datensätze\n",
      "Partition 64: 208 Datensätze\n",
      "\n",
      "\n",
      "Verarbeite 10.0% der Daten...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeitungszeit für 10.0% der Daten: 28.63 Sekunden\n",
      "Anzahl der Datensätze: 1266\n",
      "Anzahl der Partitionen: 65\n",
      "\n",
      "Anzahl der Worker Nodes: 0\n",
      "Gesamte Anzahl der Kerne: 12\n",
      "\n",
      "Verarbeite 20.0% der Daten...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeitungszeit für 20.0% der Daten: 33.01 Sekunden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Datensätze: 2475\n",
      "Anzahl der Partitionen: 65\n",
      "\n",
      "Anzahl der Worker Nodes: 0\n",
      "Gesamte Anzahl der Kerne: 12\n",
      "\n",
      "Verarbeite 50.0% der Daten...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeitungszeit für 50.0% der Daten: 43.83 Sekunden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Datensätze: 6106\n",
      "Anzahl der Partitionen: 65\n",
      "\n",
      "Anzahl der Worker Nodes: 0\n",
      "Gesamte Anzahl der Kerne: 12\n",
      "\n",
      "Verarbeite 100.0% der Daten...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeitungszeit für 100.0% der Daten: 59.21 Sekunden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 866:=========================================>            (50 + 12) / 65]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Datensätze: 12104\n",
      "Anzahl der Partitionen: 65\n",
      "\n",
      "Anzahl der Worker Nodes: 0\n",
      "Gesamte Anzahl der Kerne: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Laufzeit\n",
    "start_time = time.time()\n",
    "result_text, map_result, dataRDD = analyze_flight_movements()\n",
    "flights_rdd = restructure_flight_movements(dataRDD)    \n",
    "result, aircraft_raw_rdd, aircraftRDD = analyze_aircraft_data()\n",
    "combined_rdd = combine_rdds(flights_rdd, aircraft_raw_rdd)\n",
    "combined_analyzed_rdd, result = analyze_combined_rdd(combined_rdd)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Die Funktion hat für 100% der Daten {(end_time - start_time):.4f} Sekunden benötigt\")\n",
    "print(result)\n",
    "print()\n",
    "\n",
    "#Datenverteilung\n",
    "number_data, number_partition, result = analyze_partition_distribution(combined_analyzed_rdd)\n",
    "print(number_data + number_partition + result)\n",
    "\n",
    "\n",
    "#Skalierbarkeit\n",
    "percentages = [0.1, 0.2, 0.5, 1.0]  # 10%, 20%, 50%, 100%\n",
    "\n",
    "for percentage in percentages:\n",
    "    print(f\"\\nVerarbeite {percentage*100}% der Daten...\")\n",
    "    start_time = time.time()\n",
    "    result_text, map_result, dataRDD = analyze_flight_movements(percentage=percentage)\n",
    "    flights_rdd = restructure_flight_movements(dataRDD)\n",
    "    result, aircraft_raw_rdd, aircraftRDD = analyze_aircraft_data()\n",
    "    combined_rdd = combine_rdds(flights_rdd, aircraft_raw_rdd)\n",
    "    combined_analyzed_rdd, result = analyze_combined_rdd(combined_rdd, percentage)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Verarbeitungszeit für {percentage*100}% der Daten: {(end_time-start_time):.2f} Sekunden\")\n",
    "    number_data, number_partition, result = analyze_partition_distribution(combined_analyzed_rdd)\n",
    "    print(number_data + number_partition)\n",
    "    print(f\"Anzahl der Worker Nodes: {len(sc._jsc.sc().statusTracker().getExecutorInfos()) - 1}\")  # -1 für den Treiber\n",
    "    print(f\"Gesamte Anzahl der Kerne: {sc.defaultParallelism}\")\n",
    "\n",
    "#Fehlertoleranz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==== Test Parquet ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "#spark = SparkSession.builder \\\n",
    "#    .appName(\"Inspect Parquet\") \\\n",
    "#    .getOrCreate()\n",
    "\n",
    "#df = spark.read.parquet(\"data/bigDataSet_v2.parquet\")\n",
    "#df.show(2)  # Zeigt die ersten 5 Zeilen der Parquet-Datei\n",
    "\n",
    "#df.printSchema()\n",
    "#print(\"Spaltennamen:\", df.columns)\n",
    "\n",
    "# Umwandeln des DataFrames in ein RDD\n",
    "#rdd = df.rdd\n",
    "\n",
    "# Bereinigen der Row-Daten und Zugreifen auf die richtigen Felder\n",
    "#rdd_values = rdd.map(lambda row: (row[0].strip(), row[1], row[2], row[3]))\n",
    "\n",
    "# Ausgabe der ersten 3 Zeilen\n",
    "#print(rdd_values.take(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
